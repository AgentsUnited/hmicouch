<?xml version="1.0" encoding="ISO-8859-1" ?>
<fml-apml id="$fml_id$">
	<bml>
		<speech id="s1" start="0.0" language="english" voice="openmary" type="SAPI4" text="">
			<description level="1" type="gretabml">
				<reference>tmp/from-fml-apml.pho</reference>
			</description>
				
			<tm id="tm1"/>
				And Greta agents, are quite good at 
			<tm id="tm2"/>
				automatic non-verbal behaviour
			<tm id="tm3"/>	
				during conversation.
			<tm id="tm4"/>
				My verbal behaviour is generated from text,
			<tm id="tm5"/>	
				but my non-verbal behaviour is generated automatically.
			<tm id="tm6"/>
				I hope you have noticed these behaviours so far.
			<tm id="tm7"/>	
			
			<pitchaccent id="pa1" type="HStar" level="medium" start="s1:tm1" end="s1:tm2" importance="1"/>
			<pitchaccent id="pa2" type="HStar" level="medium" start="s1:tm2+0.3" end="s1:tm3" importance="1"/>
			<pitchaccent id="pa3" type="HStar" level="medium" start="s1:tm4" end="s1:tm4+0.5" importance="1"/>
			<pitchaccent id="pa4" type="HStar" level="medium" start="s1:tm5" end="s1:tm5+0.7" importance="1"/>
			<boundary type="LL" id="b1" start="s1:tm4" end="s1:tm4+0.5"/>
			<boundary type="LH" id="b2" start="s1:tm5" end="s1:tm5+0.5"/>
			<boundary type="LL" id="b3" start="s1:tm6" end="s1:tm6+0.5"/>
			<boundary type="LL" id="b4" start="s1:tm7" end="s1:tm7+1"/>
		</speech>
	</bml>
	<fml>
		<rest id="r1" type="restposealong_big" start="s1:tm1" end="s1:tm2" importance="1.0"/>
		<emotion id="e1" type="joyStrong" start="s1:tm1" end="s1:tm2" importance="1.0"/>
		<deictic id="d1" start="s1:tm1" end="s1:tm1+1" importance="1.0" target="head_COUCH_USER_OLD"/>
		<deictic id="d2" start="s1:tm4" end="s1:tm4+1" importance="1.0" target="head_COUCH_F_1_OLD"/>
		<deictic id="d3" start="s1:tm6" end="s1:tm6+1" importance="1.0" target="head_COUCH_USER_OLD"/>
		
	</fml>
</fml-apml>